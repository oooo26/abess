{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "This notebook introduces what is adaptive best subset selection robust principal component analysis (abessRPCA) and then we show how to use it on simulated data example. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## PCA\n",
    "\n",
    "Principal component analysis (PCA) is an important method in the field of data science, which can reduce the dimension of data and simplify our model. It actually solve an optimization problem like:\n",
    "\n",
    "$$\n",
    "    \\max_{v} v^{\\top}\\Sigma v,\\qquad s.t.\\quad v^Tv=1.\n",
    "$$\n",
    "\n",
    "where $\\Sigma = X^TX / (n-1)$ and $X$ is the **centered** sample matrix. \n",
    "Here we denote that $X$ is a $n\\times p$ matrix, where each row is an observation and each column is a variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Robust-PCA (RPCA)\n",
    "\n",
    "However, the original PCA is sensitive to outliers, which may be unavoidable in real data:\n",
    "\n",
    "- Object has extreme performance due to fortuity, but he/she shows normal in repeated test;\n",
    "- Wrong observation/recording/computing.\n",
    "\n",
    "In this situation, PCA may spend too much attention on unnecessary variables. \n",
    "That's why Robust-PCA (RPCA) is presented.\n",
    "\n",
    "In short, RPCA manages to divide the sample matrix $X$ into two parts: \n",
    "\n",
    "$$\n",
    "    X = L + S, \n",
    "$$\n",
    "\n",
    "where $L$ is the \"information\" matrix with a low rank and $S$ is the \"outlier\" sparse matrix. \n",
    "Usually, we suppose $L$ is not sparse and $S$ is not low-rank, in order to get only solution.\n",
    "\n",
    "In Largrange format, \n",
    "\n",
    "$$\n",
    "    \\min_{L, S}\\quad \\|X - L - S\\|_F \\leq \\varepsilon, \\\\\n",
    "    s.t.\\quad rank(L) = r,\\ \\|S\\|_0 \\leq s,  \n",
    "$$\n",
    "\n",
    "where $s$ is the sparsity of $S$.\n",
    "\n",
    "> Note that it does NOT deal with \"noise\", which may stay in $L$ and need further procession.  \n",
    "\n",
    "## RPCA Application\n",
    "\n",
    "Recently, RPCA is more widely used, for example,\n",
    "\n",
    "- Video Decomposition: \n",
    "in a surveillance video, the background may be unchanged for a long time while only a few pixels (e.g. people) update. \n",
    "In order to improve the efficiency of store and analysis, we need to decomposite the video into background and \n",
    "foreground. Since the background is unchanged, it can be stored well in a low-rank matrix, while the foreground, which is \n",
    "usually quite small, can be indicated by a sparse matrix. That is what RPCA does.\n",
    "\n",
    "- Face recognition: \n",
    "due to complex lighting conditions, a small part of the facial features may be unrecognized (e.g. shadow).\n",
    "In the face recognition, we need to remove the effects of shadows and focus on the face data. Actually, since the face data is\n",
    "almost unchanged (for one person), and the shadows affect only a small part, it is also a suitable situation to use RPCA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Data Example\n",
    "\n",
    "### Fitting model\n",
    "\n",
    "Now we generate an example with $100$ rows and $100$ columns. Then select $200$ position to indicate the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (100, 100)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gen_data(n, p, s, r, seed = 0):\n",
    "    np.random.seed(seed)\n",
    "    outlier = np.random.choice(n*p, s, replace=False)\n",
    "    outlier = np.vstack((outlier//p, outlier%p)).T\n",
    "    L = np.dot(np.random.rand(n, r), np.random.rand(r, n))\n",
    "    S = np.zeros((n, p))\n",
    "    S[outlier[:, 0], outlier[:, 1]] = float(np.random.randn(1)) * 10\n",
    "    X = L + S\n",
    "    return X, S\n",
    "\n",
    "n = 100     # rows\n",
    "p = 100     # columns\n",
    "s = 200     # outliers\n",
    "r = 10      # rank(L)\n",
    "\n",
    "X, S = gen_data(n, p, s, r)\n",
    "print(f'X shape: {X.shape}')\n",
    "# print(f'outlier: \\n{outlier}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use our program, an object `abessRPCA()` should be called first and given the sparsity level `support_size`. Note that the sparsity level can be a specific integer or a integer interval, which would be chosen by information criterion (e.g. GIC) adaptively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abess.pca import abessRPCA\n",
    "model = abessRPCA(support_size = s) # support_size can be a interval like `range(s_min, s_max)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite easy to fit this model, with `abessRPCA.fit` function. Given the sample matrix $X$ and $rank(L)$, the program can compute a result quickly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abessRPCA(support_size=200)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, r = r) # r=rank(L), which is set as 10 by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the fitted sparse $S$ is stored in `model.coef_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated sparsity: 200\n"
     ]
    }
   ],
   "source": [
    "S_est = model.coef_\n",
    "print(f'estimated sparsity: {np.count_nonzero(S_est)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More on the result\n",
    "\n",
    "To check the performance of the program, we use TPR, FPR as the criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TPR  FPR] = [0.925      0.00153061]\n"
     ]
    }
   ],
   "source": [
    "def TPR(pred, real):\n",
    "    TP = (pred != 0) & (real != 0)\n",
    "    P = (real != 0)\n",
    "    return sum(sum(TP)) / sum(sum(P))\n",
    "\n",
    "def FPR(pred, real):\n",
    "    FP = (pred != 0) & (real == 0)\n",
    "    N = (real == 0)\n",
    "    return sum(sum(FP)) / sum(sum(N))\n",
    "\n",
    "def test_model(pred, real):\n",
    "    tpr = TPR(pred, real)\n",
    "    fpr = FPR(pred, real)\n",
    "    return np.array([tpr, fpr])\n",
    "\n",
    "print(f'[TPR  FPR] = {test_model(S_est, S)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change different random seed like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TPR  FPR] = [0.89866667 0.00206803]\n"
     ]
    }
   ],
   "source": [
    "M = 30  # use 30 different seed\n",
    "res = np.zeros(2)\n",
    "for seed in range(M):\n",
    "    X, S = gen_data(n, p, s, r, seed)\n",
    "    model = abessRPCA(support_size=s).fit(X, r=r)\n",
    "    res += test_model(model.coef_, S)\n",
    "\n",
    "print(f'[TPR  FPR] = {res/M}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under these situations, we have a good performance."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
